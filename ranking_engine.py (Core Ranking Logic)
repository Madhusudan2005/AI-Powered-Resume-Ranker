import pdfplumber
import os
import re
import spacy
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# --- Configuration ---
# Note: User must run 'python -m spacy download en_core_web_sm'
NLP_MODEL = spacy.load('en_core_web_sm') 

# --- Utility Functions ---

def extract_text_from_pdf(pdf_path):
    """ Extracts text from a single PDF file using pdfplumber. """
    try:
        with pdfplumber.open(pdf_path) as pdf:
            text = ""
            for page in pdf.pages:
                extracted_text = page.extract_text()
                if extracted_text:
                    text += extracted_text + " "
            
            clean_text = re.sub(r'\s+', ' ', text).strip()
            return clean_text
    except Exception as e:
        return ""

def get_job_description_text(file_path):
    """ Reads the job description text from a file. """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        return f"Error: Job Description file not found at {file_path}"

def spacy_preprocessing(text):
    """
    Preprocesses text using SpaCy: lowercasing, removing stop words, 
    removing punctuation, and lemmatization.
    """
    doc = NLP_MODEL(text.lower())
    processed_tokens = []
    
    for token in doc:
        # Filter: not a stop word, not punctuation, not space, and must be alphabetic
        if not token.is_stop and not token.is_punct and not token.is_space and token.text.isalpha():
            processed_tokens.append(token.lemma_)
            
    return " ".join(processed_tokens)

# --- Core Ranking Logic ---

def rank_resumes(job_description_text, resumes_data):
    """
    Ranks resumes by matching against the Job Description using TF-IDF and 
    Cosine Similarity. Returns DataFrame with numerical scores.
    """
    
    if not job_description_text or not resumes_data:
        return pd.DataFrame({'Error': ['Missing Job Description or Resumes']})

    # 1. Preprocess all documents
    jd_processed = spacy_preprocessing(job_description_text)
    
    resume_texts_processed = []
    resume_filenames = []
    
    for resume in resumes_data:
        if 'text' in resume and resume['text']:
            resume_texts_processed.append(spacy_preprocessing(resume['text']))
            resume_filenames.append(resume['file_name'])
        
    if not resume_texts_processed:
        return pd.DataFrame({'Error': ['All resumes failed text extraction.']})

    # Combine JD and Resume texts into one corpus for TF-IDF training
    corpus = [jd_processed] + resume_texts_processed
    
    # 2. Vectorize the Corpus using TF-IDF
    vectorizer = TfidfVectorizer(max_features=5000)
    tfidf_matrix = vectorizer.fit_transform(corpus)
    
    jd_vector = tfidf_matrix[0]
    resume_vectors = tfidf_matrix[1:]
    
    # 3. Calculate Cosine Similarity
    similarity_scores = cosine_similarity(jd_vector, resume_vectors).flatten()
    
    # 4. Create and Rank DataFrame
    ranking_df = pd.DataFrame({
        'Resume_File': resume_filenames,
        'Match_Score': similarity_scores
    })
    
    ranking_df = ranking_df.sort_values(by='Match_Score', ascending=False).reset_index(drop=True)
    
    # Scale score to percentage (0-100)
    ranking_df['Match_Score'] = ranking_df['Match_Score'] * 100
    
    return ranking_df

def get_ranking_results(jd_file, resumes_dir):
    """ Wrapper function to run the entire ranking process. """
    
    # 1. Get JD text
    job_description_text = get_job_description_text(jd_file)
    if job_description_text.startswith('Error:'):
        return pd.DataFrame({'Error': [job_description_text]})

    # 2. Get all resume data
    resumes_data = []
    if os.path.exists(resumes_dir):
        for filename in os.listdir(resumes_dir):
            if filename.endswith('.pdf'):
                pdf_path = os.path.join(resumes_dir, filename)
                resume_text = extract_text_from_pdf(pdf_path)
                if resume_text:
                    resumes_data.append({
                        'file_name': filename,
                        'text': resume_text
                    })

    if not resumes_data:
        return pd.DataFrame({'Error': [f"No PDF files found or extracted in '{resumes_dir}'"]})
    
    # 3. Rank the resumes
    return rank_resumes(job_description_text, resumes_data)
